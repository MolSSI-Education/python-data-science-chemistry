{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning with Pandas\n",
    "======================\n",
    "\n",
    "<div class=\"overview\">\n",
    "   <p class=\"overview-title\">Overview</p>\n",
    "    <p>Questions</p>\n",
    "        <ul>\n",
    "            <li>Question 1\n",
    "        </ul>\n",
    "    <p>Objectives:</p>\n",
    "        <ul>\n",
    "            <li>Objective 1\n",
    "            <li>Objective 2\n",
    "        </ul>\n",
    "    <p>Keypoints:</p>\n",
    "        <ul>\n",
    "            <li>Keypoint 1</li>\n",
    "            <li>Keypoint 2</li>\n",
    "        </ul>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(\"data\", \"potts_table1.csv\")\n",
    "fpath2 = os.path.join(\"data\", \"potts_table2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = pd.read_csv(fpath)\n",
    "table2 = pd.read_csv(fpath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Compound</th>\n",
       "      <th>log P</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>II</th>\n",
       "      <th>Hy</th>\n",
       "      <th>H,</th>\n",
       "      <th>MV</th>\n",
       "      <th>R,</th>\n",
       "      <th>log Kou</th>\n",
       "      <th>log Kyex</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>log Kpep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>water</td>\n",
       "      <td>— 6.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>— 1.38</td>\n",
       "      <td>— 4,38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>'</td>\n",
       "      <td>methanol</td>\n",
       "      <td>— 6.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>—0.73</td>\n",
       "      <td>— 2.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>— 2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>methanoic acid</td>\n",
       "      <td>— 7.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>—0.54</td>\n",
       "      <td>— 3.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>— 3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ethanol</td>\n",
       "      <td>— 6.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>—0.32</td>\n",
       "      <td>—2.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ethanoic acid</td>\n",
       "      <td>—7.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.45</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>—0.31</td>\n",
       "      <td>— 3.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>—2.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Unnamed: 0.1        Compound   log P  Unnamed: 1    II    Hy  \\\n",
       "0           0          NaN           water  — 6.85         NaN  0.45  0.82   \n",
       "1           1            '        methanol  — 6.68         NaN  0.44  0.43   \n",
       "2           2          NaN  methanoic acid  — 7.08         NaN  0.60  0.75   \n",
       "3           3          NaN         ethanol  — 6.66         NaN  0.42  0.37   \n",
       "4           4          NaN   ethanoic acid   —7.01         NaN  0.65  0.61   \n",
       "\n",
       "     H,    MV    R, log Kou log Kyex  Unnamed: 2 log Kpep  \n",
       "0  0.35  10.6  0.00  — 1.38   — 4,38         NaN      NaN  \n",
       "1  0.47  21.7  0.28   —0.73   — 2.42         NaN   — 2.80  \n",
       "2  0.38  22.3  0.30   —0.54   — 3.93         NaN   — 3.63  \n",
       "3  0.48  31.9  0.25   —0.32    —2.24         NaN    —2.10  \n",
       "4  0.45  33.4  0.27   —0.31   — 3.28         NaN    —2.90  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping unneccessary data\n",
    "\n",
    "In some cases, we might have data in our dataframe that we don't need. We will want to discard or \"drop\" this data from the dataframe. For the dataframe we just loaded, for example, we can see that the data in columns 0, 1, 4, 12 won't be used. We could safely discard these from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    37 non-null     int64  \n",
      " 1   Unnamed: 0.1  1 non-null      object \n",
      " 2   Compound      37 non-null     object \n",
      " 3   log P         37 non-null     object \n",
      " 4   Unnamed: 1    0 non-null      float64\n",
      " 5   II            37 non-null     float64\n",
      " 6   Hy            37 non-null     float64\n",
      " 7   H,            37 non-null     float64\n",
      " 8   MV            37 non-null     object \n",
      " 9   R,            37 non-null     float64\n",
      " 10  log Kou       37 non-null     object \n",
      " 11  log Kyex      31 non-null     object \n",
      " 12  Unnamed: 2    0 non-null      float64\n",
      " 13  log Kpep      25 non-null     object \n",
      "dtypes: float64(6), int64(1), object(7)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods you might use to drop data from a dataframe. These are `drop`, and `dropna`. Drop is used when you have specific rows or columns you want to remove from the dataframe, while `dropna` is used when you want to drop columns or rows which contain `NaN` or \"not a number\" values. This occurs when there are no values in a data cell.\n",
    "\n",
    "In the output of `info` above, we can see that there are two columns which contain 0 non-null values. This means that all of the values in these columns are `NaN`. We can safely discard these columns. We'll use the `dropna` function to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method dropna in module pandas.core.frame:\n",
      "\n",
      "dropna(axis=0, how='any', thresh=None, subset=None, inplace=False) method of pandas.core.frame.DataFrame instance\n",
      "    Remove missing values.\n",
      "    \n",
      "    See the :ref:`User Guide <missing_data>` for more on which values are\n",
      "    considered missing, and how to work with missing data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Determine if rows or columns which contain missing values are\n",
      "        removed.\n",
      "    \n",
      "        * 0, or 'index' : Drop rows which contain missing values.\n",
      "        * 1, or 'columns' : Drop columns which contain missing value.\n",
      "    \n",
      "        .. versionchanged:: 1.0.0\n",
      "    \n",
      "           Pass tuple or list to drop on multiple axes.\n",
      "           Only a single axis is allowed.\n",
      "    \n",
      "    how : {'any', 'all'}, default 'any'\n",
      "        Determine if row or column is removed from DataFrame, when we have\n",
      "        at least one NA or all NA.\n",
      "    \n",
      "        * 'any' : If any NA values are present, drop that row or column.\n",
      "        * 'all' : If all values are NA, drop that row or column.\n",
      "    \n",
      "    thresh : int, optional\n",
      "        Require that many non-NA values.\n",
      "    subset : array-like, optional\n",
      "        Labels along other axis to consider, e.g. if you are dropping rows\n",
      "        these would be a list of columns to include.\n",
      "    inplace : bool, default False\n",
      "        If True, do operation inplace and return None.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        DataFrame with NA entries dropped from it.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.isna: Indicate missing values.\n",
      "    DataFrame.notna : Indicate existing (non-missing) values.\n",
      "    DataFrame.fillna : Replace missing values.\n",
      "    Series.dropna : Drop missing values.\n",
      "    Index.dropna : Drop missing indices.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
      "    ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
      "    ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
      "    ...                             pd.NaT]})\n",
      "    >>> df\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Drop the rows where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna()\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "    \n",
      "    Drop the columns where at least one element is missing.\n",
      "    \n",
      "    >>> df.dropna(axis='columns')\n",
      "           name\n",
      "    0    Alfred\n",
      "    1    Batman\n",
      "    2  Catwoman\n",
      "    \n",
      "    Drop the rows where all elements are missing.\n",
      "    \n",
      "    >>> df.dropna(how='all')\n",
      "           name        toy       born\n",
      "    0    Alfred        NaN        NaT\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Keep only the rows with at least 2 non-NA values.\n",
      "    \n",
      "    >>> df.dropna(thresh=2)\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    2  Catwoman   Bullwhip        NaT\n",
      "    \n",
      "    Define in which columns to look for missing values.\n",
      "    \n",
      "    >>> df.dropna(subset=['name', 'born'])\n",
      "           name        toy       born\n",
      "    1    Batman  Batmobile 1940-04-25\n",
      "    \n",
      "    Keep the DataFrame with valid entries in the same variable.\n",
      "    \n",
      "    >>> df.dropna(inplace=True)\n",
      "    >>> df\n",
      "         name        toy       born\n",
      "    1  Batman  Batmobile 1940-04-25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(table1.dropna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving the dataframe, we'll look at and and discuss output from this function. \n",
    "\n",
    "By default, the function `dropna` will work on `axis 0` or the rows of the dataframe, and will drop any row which contains a `NaN`. You will see this results in a dataframe with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Compound</th>\n",
       "      <th>log P</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>II</th>\n",
       "      <th>Hy</th>\n",
       "      <th>H,</th>\n",
       "      <th>MV</th>\n",
       "      <th>R,</th>\n",
       "      <th>log Kou</th>\n",
       "      <th>log Kyex</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>log Kpep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Unnamed: 0.1, Compound, log P, Unnamed: 1, II, Hy, H,, MV, R,, log Kou, log Kyex, Unnamed: 2, log Kpep]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `dropna` returns a dataframe and does not overwrite the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    37 non-null     int64  \n",
      " 1   Unnamed: 0.1  1 non-null      object \n",
      " 2   Compound      37 non-null     object \n",
      " 3   log P         37 non-null     object \n",
      " 4   Unnamed: 1    0 non-null      float64\n",
      " 5   II            37 non-null     float64\n",
      " 6   Hy            37 non-null     float64\n",
      " 7   H,            37 non-null     float64\n",
      " 8   MV            37 non-null     object \n",
      " 9   R,            37 non-null     float64\n",
      " 10  log Kou       37 non-null     object \n",
      " 11  log Kyex      31 non-null     object \n",
      " 12  Unnamed: 2    0 non-null      float64\n",
      " 13  log Kpep      25 non-null     object \n",
      "dtypes: float64(6), int64(1), object(7)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can switch to dropping columns which have `NaN` values by adding the argument `axis=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  37 non-null     int64  \n",
      " 1   Compound    37 non-null     object \n",
      " 2   log P       37 non-null     object \n",
      " 3   II          37 non-null     float64\n",
      " 4   Hy          37 non-null     float64\n",
      " 5   H,          37 non-null     float64\n",
      " 6   MV          37 non-null     object \n",
      " 7   R,          37 non-null     float64\n",
      " 8   log Kou     37 non-null     object \n",
      "dtypes: float64(4), int64(1), object(4)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.dropna(axis=1).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is closer to what we want. However, you'll notice that this has dropped some columns which have data. We can add `how=all` to drop only columns whose values are all `NaN`. Once we are sure we would like to keep this as our dataframe, we can add `inplace=True` to the function call to overwrite the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    37 non-null     int64  \n",
      " 1   Unnamed: 0.1  1 non-null      object \n",
      " 2   Compound      37 non-null     object \n",
      " 3   log P         37 non-null     object \n",
      " 4   II            37 non-null     float64\n",
      " 5   Hy            37 non-null     float64\n",
      " 6   H,            37 non-null     float64\n",
      " 7   MV            37 non-null     object \n",
      " 8   R,            37 non-null     float64\n",
      " 9   log Kou       37 non-null     object \n",
      " 10  log Kyex      31 non-null     object \n",
      " 11  log Kpep      25 non-null     object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 3.6+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop the final two columns using the `drop` function. You can use this when you have specific rows or columns you would like to discard. Again, we use `axis=1` to drop columns, then we pass the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.drop(axis=1, columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Compound  37 non-null     object \n",
      " 1   log P     37 non-null     object \n",
      " 2   II        37 non-null     float64\n",
      " 3   Hy        37 non-null     float64\n",
      " 4   H,        37 non-null     float64\n",
      " 5   MV        37 non-null     object \n",
      " 6   R,        37 non-null     float64\n",
      " 7   log Kou   37 non-null     object \n",
      " 8   log Kyex  31 non-null     object \n",
      " 9   log Kpep  25 non-null     object \n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might now want to clean up the column names and make sure they are descriptive. You can see the column names using `table1.columns`. You can either rename the columns by setting `table1.columns` to a list of the appropriate length, or you can use `table1.rename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Compound', 'log P', 'II', 'Hy', 'H,', 'MV', 'R,', 'log Kou',\n",
       "       'log Kyex', 'log Kpep'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.rename(inplace=True, columns={\n",
    "    \"II\": \"pi\", \n",
    "    \"Hy\": \"Hd\", \n",
    "    \"H,\": \"Ha\", \n",
    "    \"R,\": \"R_2\",\n",
    "    \"log Kou\": \"log K_oct\",\n",
    "    \"log Kyex\": \"log K_hex\",\n",
    "    \"log Kpep\": \"log K_hep\"\n",
    "                      \n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>log P</th>\n",
       "      <th>pi</th>\n",
       "      <th>Hd</th>\n",
       "      <th>Ha</th>\n",
       "      <th>MV</th>\n",
       "      <th>R_2</th>\n",
       "      <th>log K_oct</th>\n",
       "      <th>log K_hex</th>\n",
       "      <th>log K_hep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>— 6.85</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>— 1.38</td>\n",
       "      <td>— 4,38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>methanol</td>\n",
       "      <td>— 6.68</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.28</td>\n",
       "      <td>—0.73</td>\n",
       "      <td>— 2.42</td>\n",
       "      <td>— 2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>methanoic acid</td>\n",
       "      <td>— 7.08</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.38</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>—0.54</td>\n",
       "      <td>— 3.93</td>\n",
       "      <td>— 3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethanol</td>\n",
       "      <td>— 6.66</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>—0.32</td>\n",
       "      <td>—2.24</td>\n",
       "      <td>—2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ethanoic acid</td>\n",
       "      <td>—7.01</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.45</td>\n",
       "      <td>33.4</td>\n",
       "      <td>0.27</td>\n",
       "      <td>—0.31</td>\n",
       "      <td>— 3.28</td>\n",
       "      <td>—2.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Compound   log P    pi    Hd    Ha    MV   R_2 log K_oct log K_hex  \\\n",
       "0           water  — 6.85  0.45  0.82  0.35  10.6  0.00    — 1.38    — 4,38   \n",
       "1        methanol  — 6.68  0.44  0.43  0.47  21.7  0.28     —0.73    — 2.42   \n",
       "2  methanoic acid  — 7.08  0.60  0.75  0.38  22.3  0.30     —0.54    — 3.93   \n",
       "3         ethanol  — 6.66  0.42  0.37  0.48  31.9  0.25     —0.32     —2.24   \n",
       "4   ethanoic acid   —7.01  0.65  0.61  0.45  33.4  0.27     —0.31    — 3.28   \n",
       "\n",
       "  log K_hep  \n",
       "0       NaN  \n",
       "1    — 2.80  \n",
       "2    — 3.63  \n",
       "3     —2.10  \n",
       "4     —2.90  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When examining `.info` , you'll notice that a lot of our columns which should be numbers are still 'objects' or strings. We would like `log P`, for example to be numeric. There are a few ways to do this, but we'll use the pandas function `to_numeric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Compound   37 non-null     object \n",
      " 1   log P      37 non-null     object \n",
      " 2   pi         37 non-null     float64\n",
      " 3   Hd         37 non-null     float64\n",
      " 4   Ha         37 non-null     float64\n",
      " 5   MV         37 non-null     object \n",
      " 6   R_2        37 non-null     float64\n",
      " 7   log K_oct  37 non-null     object \n",
      " 8   log K_hex  31 non-null     object \n",
      " 9   log K_hep  25 non-null     object \n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `to_numeric` function without any additional inputs will fail on this data set, however, because of the characters used for minus signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"— 6.85\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"— 6.85\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b00e34002272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"log P\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             values = lib.maybe_convert_numeric(\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"— 6.85\" at position 0"
     ]
    }
   ],
   "source": [
    "pd.to_numeric(table1[\"log P\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could choose to handle the errors differently. For example, you could set errors to be ignored (which would result in the column being unchanged, there would just be no error raised) or to \"coerce\" the values. Choosing \"coerce\" means that anything that can't be cast as numeric will be put as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "5    NaN\n",
       "6    NaN\n",
       "7    NaN\n",
       "8    NaN\n",
       "9    NaN\n",
       "10   NaN\n",
       "11   NaN\n",
       "12   NaN\n",
       "13   NaN\n",
       "14   NaN\n",
       "15   NaN\n",
       "16   NaN\n",
       "17   NaN\n",
       "18   NaN\n",
       "19   NaN\n",
       "20   NaN\n",
       "21   NaN\n",
       "22   NaN\n",
       "23   NaN\n",
       "24   NaN\n",
       "25   NaN\n",
       "26   NaN\n",
       "27   NaN\n",
       "28   NaN\n",
       "29   NaN\n",
       "30   NaN\n",
       "31   NaN\n",
       "32   NaN\n",
       "33   NaN\n",
       "34   NaN\n",
       "35   NaN\n",
       "36   NaN\n",
       "Name: log P, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(table1[\"log P\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to do a little bit more processing to the values for this to work. If you examine the columns, you may notice that the negative sign is a little off. It is `—` when it should be `-`. This is very slight, and might be hard to see, but it is important to change for this data set.\n",
    "\n",
    "We will want to replace all `—` with `-`. We could accomplish this using the string method `replace`. Strings in Python have a number of methods. The `replace` method allows us to replace a substring within a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"Hello world.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string.replace(\".\", \"!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split command is another string method you are probably familiar with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'world.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas string methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use these on a column in a pandas dataframe, you might think to use `apply`, which we learned about in the last session. However, you will notice that the `replace` method acts on a the string and doesn't fit into `apply`.\n",
    "\n",
    "Luckily, when pandas columns are strings, we can use string methods on the whole column by adding `.str.function`. For example, to replace the minus signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      - 6.85\n",
       "1      - 6.68\n",
       "2      - 7.08\n",
       "3      - 6.66\n",
       "4       -7.01\n",
       "5      - 6.41\n",
       "6       -7.01\n",
       "7      - 5.90\n",
       "8     -4,.5]1\n",
       "9      - 5.35\n",
       "10     - 6.16\n",
       "11     - 6.36\n",
       "12     - 5.64\n",
       "13     - 3.56\n",
       "14     - 3.75\n",
       "15     - 5.78\n",
       "16     - 5.78\n",
       "17      -6.01\n",
       "18     - 5.04\n",
       "19     - 5.00\n",
       "20     - 5.38\n",
       "21    ~- 5,36\n",
       "22     - 5.29\n",
       "23     - 5.00\n",
       "24      -5.81\n",
       "25      -5.81\n",
       "26     - 4,56\n",
       "27     - 3.48\n",
       "28      -5.45\n",
       "29      -5.44\n",
       "30      -5.11\n",
       "31     - 5.05\n",
       "32     - 5.28\n",
       "33     - 4.84\n",
       "34      -5.21\n",
       "35      -4.77\n",
       "36     - 4.66\n",
       "Name: log P, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table1[\"log P\"].str.replace(\"—\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1[\"log P\"] = table1[\"log P\"].str.replace(\"—\", \"-\")\n",
    "\n",
    "# We still need to get rid of spaces\n",
    "table1[\"log P\"] = table1[\"log P\"].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1[\"log P\"] =  pd.to_numeric(table1[\"log P\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Compound   37 non-null     object \n",
      " 1   log P      34 non-null     float64\n",
      " 2   pi         37 non-null     float64\n",
      " 3   Hd         37 non-null     float64\n",
      " 4   Ha         37 non-null     float64\n",
      " 5   MV         37 non-null     object \n",
      " 6   R_2        37 non-null     float64\n",
      " 7   log K_oct  37 non-null     object \n",
      " 8   log K_hex  31 non-null     object \n",
      " 9   log K_hep  25 non-null     object \n",
      "dtypes: float64(5), object(5)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We actually need to change this character on all of our columns. However `str` methods only work on pandas series. If we want to replace a string across all of our DataFrame, we will use the `.replace` method. In order for it to recognize substrings, set the option `regex=True`. We will discuss `regex` more in the next session, but this is all you need to know about regex for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.replace(\"—\", \"-\", regex=True, inplace=True)\n",
    "table1.replace(\" \", \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the data type of multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the data type of multiple columns, we will want to use the `pd.to_numeric` function on all of those columns. There are several ways you might choose to do this. For example, you might just choose to call the function for each column.\n",
    "\n",
    "We can also accomplish this by using the `apply` operator which we learned about in the last session. The `apply` operator should be used whenever you want to apply a function to a row or column. In this case, we want to apply the `pd.to_numeric` function to each column.\n",
    "\n",
    "Because we want to apply to the columns, we add the argument `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"water\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"water\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-19256207bc24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7543\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7544\u001b[0m         )\n\u001b[0;32m-> 7545\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             values = lib.maybe_convert_numeric(\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"water\" at position 0"
     ]
    }
   ],
   "source": [
    "table1.apply(pd.to_numeric, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we try this code, we immediately see an error. We do not want to try to convert the first column to a number. We can use the `iloc` function to exclude the first column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"-4,38\" at position 7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"-4,38\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-794ce36e093b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7543\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7544\u001b[0m         )\n\u001b[0;32m-> 7545\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfizer_pt2/lib/python3.7/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             values = lib.maybe_convert_numeric(\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             )\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"-4,38\" at position 7"
     ]
    }
   ],
   "source": [
    "table1.iloc[:, 1:].apply(pd.to_numeric, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error again! This time, we see failure because a string was incorrectly read from the pdf and could not be converted to a number. You could choose to handle this differently, but for this workshop we are just going to discard values like these. \n",
    "\n",
    "If we were using `to_numeric` on a pandas series, we would use the option `errors=\"coerce\"`. You may not see immediately how to use this with the `apply` function, but fortunately, pandas allows us to pass additional arguments with `apply`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.iloc[:, 1:] = table1.iloc[:, 1:].apply(pd.to_numeric, axis=1, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Compound   37 non-null     object \n",
      " 1   log P      34 non-null     float64\n",
      " 2   pi         37 non-null     float64\n",
      " 3   Hd         37 non-null     float64\n",
      " 4   Ha         37 non-null     float64\n",
      " 5   MV         36 non-null     float64\n",
      " 6   R_2        37 non-null     float64\n",
      " 7   log K_oct  36 non-null     float64\n",
      " 8   log K_hex  30 non-null     float64\n",
      " 9   log K_hep  24 non-null     float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "table1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1.to_csv(\"data/potts_table1_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
